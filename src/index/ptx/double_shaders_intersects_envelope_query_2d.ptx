//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-33191640
// Cuda compilation tools, release 12.2, V12.2.140
// Based on NVVM 7.0.1
//

.version 8.2
.target sm_75
.address_size 64

	// .globl	__intersection__intersects_envelope_query_2d_forward
.weak .global .align 4 .b8 _ZZN4cuda3std3__48__detail21__stronger_order_cudaEiiE7__xform[16] = {3, 0, 0, 0, 4, 0, 0, 0, 4, 0, 0, 0, 3};
.global .align 1 .b8 __nv_static_61__a6b88e57_39_shaders_intersects_envelope_query_2d_cu_71bf3302__ZN70_INTERNAL_a6b88e57_39_shaders_intersects_envelope_query_2d_cu_71bf33026thrust6system6detail10sequential3seqE[1];
.global .align 1 .b8 __nv_static_61__a6b88e57_39_shaders_intersects_envelope_query_2d_cu_71bf3302__ZN70_INTERNAL_a6b88e57_39_shaders_intersects_envelope_query_2d_cu_71bf33026thrust8cuda_cub3parE[1];
.global .align 1 .b8 __nv_static_61__a6b88e57_39_shaders_intersects_envelope_query_2d_cu_71bf3302__ZN70_INTERNAL_a6b88e57_39_shaders_intersects_envelope_query_2d_cu_71bf33026thrust8cuda_cub10par_nosyncE[1];
.global .align 1 .b8 __nv_static_61__a6b88e57_39_shaders_intersects_envelope_query_2d_cu_71bf3302__ZN70_INTERNAL_a6b88e57_39_shaders_intersects_envelope_query_2d_cu_71bf33026thrust12placeholders2_1E[1];
.global .align 1 .b8 __nv_static_61__a6b88e57_39_shaders_intersects_envelope_query_2d_cu_71bf3302__ZN70_INTERNAL_a6b88e57_39_shaders_intersects_envelope_query_2d_cu_71bf33026thrust12placeholders2_2E[1];
.global .align 1 .b8 __nv_static_61__a6b88e57_39_shaders_intersects_envelope_query_2d_cu_71bf3302__ZN70_INTERNAL_a6b88e57_39_shaders_intersects_envelope_query_2d_cu_71bf33026thrust12placeholders2_3E[1];
.global .align 1 .b8 __nv_static_61__a6b88e57_39_shaders_intersects_envelope_query_2d_cu_71bf3302__ZN70_INTERNAL_a6b88e57_39_shaders_intersects_envelope_query_2d_cu_71bf33026thrust12placeholders2_4E[1];
.global .align 1 .b8 __nv_static_61__a6b88e57_39_shaders_intersects_envelope_query_2d_cu_71bf3302__ZN70_INTERNAL_a6b88e57_39_shaders_intersects_envelope_query_2d_cu_71bf33026thrust12placeholders2_5E[1];
.global .align 1 .b8 __nv_static_61__a6b88e57_39_shaders_intersects_envelope_query_2d_cu_71bf3302__ZN70_INTERNAL_a6b88e57_39_shaders_intersects_envelope_query_2d_cu_71bf33026thrust12placeholders2_6E[1];
.global .align 1 .b8 __nv_static_61__a6b88e57_39_shaders_intersects_envelope_query_2d_cu_71bf3302__ZN70_INTERNAL_a6b88e57_39_shaders_intersects_envelope_query_2d_cu_71bf33026thrust12placeholders2_7E[1];
.global .align 1 .b8 __nv_static_61__a6b88e57_39_shaders_intersects_envelope_query_2d_cu_71bf3302__ZN70_INTERNAL_a6b88e57_39_shaders_intersects_envelope_query_2d_cu_71bf33026thrust12placeholders2_8E[1];
.global .align 1 .b8 __nv_static_61__a6b88e57_39_shaders_intersects_envelope_query_2d_cu_71bf3302__ZN70_INTERNAL_a6b88e57_39_shaders_intersects_envelope_query_2d_cu_71bf33026thrust12placeholders2_9E[1];
.global .align 1 .b8 __nv_static_61__a6b88e57_39_shaders_intersects_envelope_query_2d_cu_71bf3302__ZN70_INTERNAL_a6b88e57_39_shaders_intersects_envelope_query_2d_cu_71bf33026thrust12placeholders3_10E[1];
.global .align 1 .b8 __nv_static_61__a6b88e57_39_shaders_intersects_envelope_query_2d_cu_71bf3302__ZN70_INTERNAL_a6b88e57_39_shaders_intersects_envelope_query_2d_cu_71bf33026thrust3seqE[1];
.global .align 1 .b8 __nv_static_61__a6b88e57_39_shaders_intersects_envelope_query_2d_cu_71bf3302__ZN70_INTERNAL_a6b88e57_39_shaders_intersects_envelope_query_2d_cu_71bf33024cuda3std3__48in_placeE[1];
.global .align 1 .b8 __nv_static_61__a6b88e57_39_shaders_intersects_envelope_query_2d_cu_71bf3302__ZN70_INTERNAL_a6b88e57_39_shaders_intersects_envelope_query_2d_cu_71bf33024cuda3std6ranges3__45__cpo4swapE[1];
.global .align 1 .b8 __nv_static_61__a6b88e57_39_shaders_intersects_envelope_query_2d_cu_71bf3302__ZN70_INTERNAL_a6b88e57_39_shaders_intersects_envelope_query_2d_cu_71bf33024cuda3std6ranges3__45__cpo9iter_moveE[1];
.extern .const .align 8 .b8 params[64];

.visible .entry __intersection__intersects_envelope_query_2d_forward()
{
	.reg .pred 	%p<16>;
	.reg .f32 	%f<4>;
	.reg .b32 	%r<7>;
	.reg .f64 	%fd<58>;
	.reg .b64 	%rd<22>;


	// begin inline asm
	call (%r2), _optix_read_primitive_idx, ();
	// end inline asm
	mov.u32 	%r4, 0;
	// begin inline asm
	call (%r3), _optix_get_payload, (%r4);
	// end inline asm
	// begin inline asm
	call (%r5), _optix_read_instance_id, ();
	// end inline asm
	ld.const.u64 	%rd3, [params];
	cvta.to.global.u64 	%rd4, %rd3;
	mul.wide.u32 	%rd5, %r5, 8;
	add.s64 	%rd6, %rd4, %rd5;
	cvt.u64.u32 	%rd7, %r2;
	ld.global.u64 	%rd8, [%rd6];
	add.s64 	%rd1, %rd8, %rd7;
	ld.const.u64 	%rd9, [params+16];
	cvta.to.global.u64 	%rd10, %rd9;
	ld.const.u64 	%rd11, [params+32];
	cvta.to.global.u64 	%rd12, %rd11;
	mul.wide.u32 	%rd13, %r3, 32;
	add.s64 	%rd14, %rd12, %rd13;
	ld.global.v2.f64 	{%fd14, %fd15}, [%rd14+16];
	ld.global.v2.f64 	{%fd16, %fd17}, [%rd14];
	sub.f64 	%fd18, %fd16, %fd14;
	mov.f32 	%f1, 0f7F800000;
	abs.f32 	%f2, %f1;
	setp.gtu.f32 	%p1, %f2, 0f7F800000;
	selp.f32 	%f3, 0f7F800000, 0f3F800001, %p1;
	cvt.f64.f32 	%fd5, %f3;
	shl.b64 	%rd15, %rd1, 5;
	add.s64 	%rd2, %rd10, %rd15;
	rcp.rn.f64 	%fd19, %fd18;
	ld.global.f64 	%fd6, [%rd2];
	sub.f64 	%fd20, %fd6, %fd14;
	mul.f64 	%fd21, %fd19, %fd20;
	ld.global.f64 	%fd7, [%rd2+16];
	sub.f64 	%fd22, %fd7, %fd14;
	mul.f64 	%fd23, %fd19, %fd22;
	setp.gt.f64 	%p2, %fd21, %fd23;
	selp.f64 	%fd24, %fd21, %fd23, %p2;
	selp.f64 	%fd25, %fd23, %fd21, %p2;
	mul.f64 	%fd26, %fd24, 0d3FF0000000000006;
	max.f64 	%fd8, %fd25, 0d0000000000000000;
	setp.lt.f64 	%p3, %fd26, %fd5;
	selp.f64 	%fd9, %fd26, %fd5, %p3;
	setp.gt.f64 	%p4, %fd8, %fd9;
	@%p4 bra 	$L__BB0_5;

	sub.f64 	%fd27, %fd15, %fd17;
	rcp.rn.f64 	%fd28, %fd27;
	ld.global.f64 	%fd10, [%rd2+8];
	sub.f64 	%fd29, %fd10, %fd17;
	mul.f64 	%fd30, %fd28, %fd29;
	ld.global.f64 	%fd11, [%rd2+24];
	sub.f64 	%fd31, %fd11, %fd17;
	mul.f64 	%fd32, %fd28, %fd31;
	setp.gt.f64 	%p5, %fd30, %fd32;
	selp.f64 	%fd33, %fd30, %fd32, %p5;
	selp.f64 	%fd34, %fd32, %fd30, %p5;
	mul.f64 	%fd35, %fd33, 0d3FF0000000000006;
	setp.gt.f64 	%p6, %fd34, %fd8;
	selp.f64 	%fd36, %fd34, %fd8, %p6;
	setp.lt.f64 	%p7, %fd35, %fd9;
	selp.f64 	%fd37, %fd35, %fd9, %p7;
	setp.gt.f64 	%p8, %fd36, %fd37;
	@%p8 bra 	$L__BB0_5;

	sub.f64 	%fd38, %fd7, %fd6;
	rcp.rn.f64 	%fd39, %fd38;
	sub.f64 	%fd40, %fd16, %fd6;
	mul.f64 	%fd41, %fd39, %fd40;
	sub.f64 	%fd42, %fd14, %fd6;
	mul.f64 	%fd43, %fd39, %fd42;
	setp.gt.f64 	%p9, %fd41, %fd43;
	selp.f64 	%fd44, %fd41, %fd43, %p9;
	selp.f64 	%fd45, %fd43, %fd41, %p9;
	mul.f64 	%fd46, %fd44, 0d3FF0000000000006;
	max.f64 	%fd12, %fd45, 0d0000000000000000;
	setp.lt.f64 	%p10, %fd46, %fd5;
	selp.f64 	%fd13, %fd46, %fd5, %p10;
	setp.gt.f64 	%p11, %fd12, %fd13;
	@%p11 bra 	$L__BB0_4;

	sub.f64 	%fd47, %fd11, %fd10;
	rcp.rn.f64 	%fd48, %fd47;
	sub.f64 	%fd49, %fd17, %fd10;
	mul.f64 	%fd50, %fd48, %fd49;
	sub.f64 	%fd51, %fd15, %fd10;
	mul.f64 	%fd52, %fd48, %fd51;
	setp.gt.f64 	%p12, %fd50, %fd52;
	selp.f64 	%fd53, %fd50, %fd52, %p12;
	selp.f64 	%fd54, %fd52, %fd50, %p12;
	mul.f64 	%fd55, %fd53, 0d3FF0000000000006;
	setp.gt.f64 	%p13, %fd54, %fd12;
	selp.f64 	%fd56, %fd54, %fd12, %p13;
	setp.lt.f64 	%p14, %fd55, %fd13;
	selp.f64 	%fd57, %fd55, %fd13, %p14;
	setp.leu.f64 	%p15, %fd56, %fd57;
	@%p15 bra 	$L__BB0_5;

$L__BB0_4:
	ld.const.u64 	%rd16, [params+56];
	cvta.to.global.u64 	%rd17, %rd16;
	ld.global.u64 	%rd18, [%rd17+16];
	atom.add.u32 	%r6, [%rd18], 1;
	ld.global.u64 	%rd19, [%rd17];
	mul.wide.u32 	%rd20, %r6, 8;
	add.s64 	%rd21, %rd19, %rd20;
	st.u32 	[%rd21], %rd1;
	st.u32 	[%rd21+4], %r3;

$L__BB0_5:
	ret;

}
	// .globl	__raygen__intersects_envelope_query_2d_forward
.visible .entry __raygen__intersects_envelope_query_2d_forward()
{
	.reg .pred 	%p<3>;
	.reg .f32 	%f<10>;
	.reg .b32 	%r<82>;
	.reg .f64 	%fd<11>;
	.reg .b64 	%rd<12>;


	// begin inline asm
	call (%r81), _optix_get_launch_index_x, ();
	// end inline asm
	cvt.u64.u32 	%rd11, %r81;
	ld.const.u64 	%rd2, [params+40];
	setp.le.u64 	%p1, %rd2, %rd11;
	@%p1 bra 	$L__BB1_3;

	ld.const.u64 	%rd7, [params+32];
	cvta.to.global.u64 	%rd3, %rd7;
	ld.const.u64 	%rd4, [params+48];
	// begin inline asm
	call (%r78), _optix_get_launch_dimension_x, ();
	// end inline asm

$L__BB1_2:
	shl.b64 	%rd9, %rd11, 5;
	add.s64 	%rd10, %rd3, %rd9;
	ld.global.v2.f64 	{%fd1, %fd2}, [%rd10+16];
	mov.u32 	%r77, 0;
	mov.u32 	%r45, 1;
	ld.global.v2.f64 	{%fd5, %fd6}, [%rd10];
	sub.f64 	%fd9, %fd5, %fd1;
	sub.f64 	%fd10, %fd2, %fd6;
	cvt.rn.f32.f64 	%f1, %fd1;
	cvt.rn.f32.f64 	%f2, %fd6;
	cvt.rn.f32.f64 	%f4, %fd9;
	cvt.rn.f32.f64 	%f5, %fd10;
	mov.f32 	%f8, 0f3F800000;
	mov.f32 	%f9, 0f00000000;
	mov.u32 	%r40, 255;
	// begin inline asm
	call(%r7,%r8,%r9,%r10,%r11,%r12,%r13,%r14,%r15,%r16,%r17,%r18,%r19,%r20,%r21,%r22,%r23,%r24,%r25,%r26,%r27,%r28,%r29,%r30,%r31,%r32,%r33,%r34,%r35,%r36,%r37,%r38),_optix_trace_typed_32,(%r77,%rd4,%f1,%f2,%f9,%f4,%f5,%f9,%f9,%f8,%f9,%r40,%r77,%r77,%r45,%r77,%r45,%r81,%r77,%r77,%r77,%r77,%r77,%r77,%r77,%r77,%r77,%r77,%r77,%r77,%r77,%r77,%r77,%r77,%r77,%r77,%r77,%r77,%r77,%r77,%r77,%r77,%r77,%r77,%r77,%r77,%r77,%r77,%r77);
	// end inline asm
	add.s32 	%r81, %r78, %r7;
	cvt.u64.u32 	%rd11, %r81;
	setp.gt.u64 	%p2, %rd2, %rd11;
	@%p2 bra 	$L__BB1_2;

$L__BB1_3:
	ret;

}
	// .globl	__intersection__intersects_envelope_query_2d_backward
.visible .entry __intersection__intersects_envelope_query_2d_backward()
{
	.reg .pred 	%p<10>;
	.reg .f32 	%f<4>;
	.reg .b32 	%r<13>;
	.reg .f64 	%fd<36>;
	.reg .b64 	%rd<15>;


	// begin inline asm
	call (%r3), _optix_read_primitive_idx, ();
	// end inline asm
	mov.u32 	%r5, 0;
	// begin inline asm
	call (%r4), _optix_get_payload, (%r5);
	// end inline asm
	mov.u32 	%r7, 1;
	// begin inline asm
	call (%r6), _optix_get_payload, (%r7);
	// end inline asm
	// begin inline asm
	call (%r9), _optix_get_launch_dimension_y, ();
	// end inline asm
	rem.u32 	%r11, %r3, %r9;
	setp.ne.s32 	%p1, %r6, %r11;
	@%p1 bra 	$L__BB2_4;

	ld.const.u64 	%rd2, [params+16];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.const.u64 	%rd4, [params+32];
	cvta.to.global.u64 	%rd5, %rd4;
	mul.wide.u32 	%rd6, %r4, 32;
	add.s64 	%rd7, %rd3, %rd6;
	ld.global.v2.f64 	{%fd7, %fd8}, [%rd7];
	ld.global.v2.f64 	{%fd9, %fd10}, [%rd7+16];
	sub.f64 	%fd11, %fd9, %fd7;
	mov.f32 	%f1, 0f7F800000;
	abs.f32 	%f2, %f1;
	setp.gtu.f32 	%p2, %f2, 0f7F800000;
	selp.f32 	%f3, 0f7F800000, 0f3F800001, %p2;
	cvt.f64.f32 	%fd12, %f3;
	mul.wide.u32 	%rd8, %r3, 32;
	add.s64 	%rd1, %rd5, %rd8;
	rcp.rn.f64 	%fd13, %fd11;
	ld.global.f64 	%fd14, [%rd1];
	sub.f64 	%fd15, %fd14, %fd7;
	mul.f64 	%fd16, %fd13, %fd15;
	ld.global.f64 	%fd17, [%rd1+16];
	sub.f64 	%fd18, %fd17, %fd7;
	mul.f64 	%fd19, %fd13, %fd18;
	setp.gt.f64 	%p3, %fd16, %fd19;
	selp.f64 	%fd20, %fd16, %fd19, %p3;
	selp.f64 	%fd21, %fd19, %fd16, %p3;
	mul.f64 	%fd22, %fd20, 0d3FF0000000000006;
	max.f64 	%fd5, %fd21, 0d0000000000000000;
	setp.lt.f64 	%p4, %fd22, %fd12;
	selp.f64 	%fd6, %fd22, %fd12, %p4;
	setp.gt.f64 	%p5, %fd5, %fd6;
	@%p5 bra 	$L__BB2_4;

	sub.f64 	%fd23, %fd10, %fd8;
	rcp.rn.f64 	%fd24, %fd23;
	ld.global.f64 	%fd25, [%rd1+8];
	sub.f64 	%fd26, %fd25, %fd8;
	mul.f64 	%fd27, %fd24, %fd26;
	ld.global.f64 	%fd28, [%rd1+24];
	sub.f64 	%fd29, %fd28, %fd8;
	mul.f64 	%fd30, %fd24, %fd29;
	setp.gt.f64 	%p6, %fd27, %fd30;
	selp.f64 	%fd31, %fd27, %fd30, %p6;
	selp.f64 	%fd32, %fd30, %fd27, %p6;
	mul.f64 	%fd33, %fd31, 0d3FF0000000000006;
	setp.gt.f64 	%p7, %fd32, %fd5;
	selp.f64 	%fd34, %fd32, %fd5, %p7;
	setp.lt.f64 	%p8, %fd33, %fd6;
	selp.f64 	%fd35, %fd33, %fd6, %p8;
	setp.gt.f64 	%p9, %fd34, %fd35;
	@%p9 bra 	$L__BB2_4;

	ld.const.u64 	%rd9, [params+56];
	cvta.to.global.u64 	%rd10, %rd9;
	ld.global.u64 	%rd11, [%rd10+16];
	atom.add.u32 	%r12, [%rd11], 1;
	ld.global.u64 	%rd12, [%rd10];
	mul.wide.u32 	%rd13, %r12, 8;
	add.s64 	%rd14, %rd12, %rd13;
	st.u32 	[%rd14], %r4;
	st.u32 	[%rd14+4], %r3;

$L__BB2_4:
	ret;

}
	// .globl	__raygen__intersects_envelope_query_2d_backward
.visible .entry __raygen__intersects_envelope_query_2d_backward()
{
	.reg .pred 	%p<6>;
	.reg .b16 	%rs<5>;
	.reg .f32 	%f<10>;
	.reg .b32 	%r<89>;
	.reg .f64 	%fd<9>;
	.reg .b64 	%rd<12>;


	// begin inline asm
	call (%r88), _optix_get_launch_index_x, ();
	// end inline asm
	cvt.u64.u32 	%rd11, %r88;
	ld.const.u64 	%rd2, [params+24];
	setp.le.u64 	%p1, %rd2, %rd11;
	@%p1 bra 	$L__BB3_7;

	ld.const.u64 	%rd8, [params+16];
	cvta.to.global.u64 	%rd3, %rd8;
	ld.const.u64 	%rd4, [params+48];
	// begin inline asm
	call (%r11), _optix_get_launch_index_y, ();
	// end inline asm
	cvt.rn.f32.u32 	%f3, %r11;
	// begin inline asm
	call (%r84), _optix_get_launch_dimension_x, ();
	// end inline asm

$L__BB3_2:
	shl.b64 	%rd9, %rd11, 5;
	add.s64 	%rd6, %rd3, %rd9;
	ld.global.f64 	%fd1, [%rd6+16];
	ld.global.f64 	%fd2, [%rd6];
	setp.geu.f64 	%p2, %fd2, %fd1;
	mov.u16 	%rs4, 0;
	@%p2 bra 	$L__BB3_4;

	ld.global.f64 	%fd3, [%rd6+24];
	ld.global.f64 	%fd4, [%rd6+8];
	setp.lt.f64 	%p3, %fd4, %fd3;
	selp.u16 	%rs4, 1, 0, %p3;

$L__BB3_4:
	setp.eq.s16 	%p4, %rs4, 0;
	@%p4 bra 	$L__BB3_6;

	ld.global.f64 	%fd5, [%rd6+24];
	ld.global.f64 	%fd6, [%rd6+8];
	sub.f64 	%fd7, %fd5, %fd6;
	cvt.rn.f32.f64 	%f2, %fd6;
	sub.f64 	%fd8, %fd1, %fd2;
	cvt.rn.f32.f64 	%f4, %fd8;
	cvt.rn.f32.f64 	%f5, %fd7;
	cvt.rn.f32.f64 	%f1, %fd2;
	mov.f32 	%f8, 0f3F800000;
	mov.f32 	%f9, 0f00000000;
	mov.u32 	%r46, 255;
	mov.u32 	%r49, 1;
	mov.u32 	%r51, 2;
	mov.u32 	%r83, 0;
	// begin inline asm
	call(%r88,%r14,%r15,%r16,%r17,%r18,%r19,%r20,%r21,%r22,%r23,%r24,%r25,%r26,%r27,%r28,%r29,%r30,%r31,%r32,%r33,%r34,%r35,%r36,%r37,%r38,%r39,%r40,%r41,%r42,%r43,%r44),_optix_trace_typed_32,(%r83,%rd4,%f1,%f2,%f3,%f4,%f5,%f9,%f9,%f8,%f9,%r46,%r83,%r83,%r49,%r83,%r51,%r88,%r11,%r83,%r83,%r83,%r83,%r83,%r83,%r83,%r83,%r83,%r83,%r83,%r83,%r83,%r83,%r83,%r83,%r83,%r83,%r83,%r83,%r83,%r83,%r83,%r83,%r83,%r83,%r83,%r83,%r83,%r83);
	// end inline asm

$L__BB3_6:
	add.s32 	%r88, %r84, %r88;
	cvt.u64.u32 	%rd11, %r88;
	setp.gt.u64 	%p5, %rd2, %rd11;
	@%p5 bra 	$L__BB3_2;

$L__BB3_7:
	ret;

}
	// .weak	_ZN3cub17CUB_200200_750_NS11EmptyKernelIvEEvv
.weak .entry _ZN3cub17CUB_200200_750_NS11EmptyKernelIvEEvv()
{



	ret;

}

