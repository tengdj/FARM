//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-33191640
// Cuda compilation tools, release 12.2, V12.2.140
// Based on NVVM 7.0.1
//

.version 8.2
.target sm_75
.address_size 64

	// .globl	__intersection__intersects_line_query_2d
.weak .global .align 4 .b8 _ZZN4cuda3std3__48__detail21__stronger_order_cudaEiiE7__xform[16] = {3, 0, 0, 0, 4, 0, 0, 0, 4, 0, 0, 0, 3};
.global .align 1 .b8 __nv_static_57__1ac03b01_35_shaders_intersects_line_query_2d_cu_76da30a3__ZN66_INTERNAL_1ac03b01_35_shaders_intersects_line_query_2d_cu_76da30a36thrust6system6detail10sequential3seqE[1];
.global .align 1 .b8 __nv_static_57__1ac03b01_35_shaders_intersects_line_query_2d_cu_76da30a3__ZN66_INTERNAL_1ac03b01_35_shaders_intersects_line_query_2d_cu_76da30a36thrust8cuda_cub3parE[1];
.global .align 1 .b8 __nv_static_57__1ac03b01_35_shaders_intersects_line_query_2d_cu_76da30a3__ZN66_INTERNAL_1ac03b01_35_shaders_intersects_line_query_2d_cu_76da30a36thrust8cuda_cub10par_nosyncE[1];
.global .align 1 .b8 __nv_static_57__1ac03b01_35_shaders_intersects_line_query_2d_cu_76da30a3__ZN66_INTERNAL_1ac03b01_35_shaders_intersects_line_query_2d_cu_76da30a36thrust12placeholders2_1E[1];
.global .align 1 .b8 __nv_static_57__1ac03b01_35_shaders_intersects_line_query_2d_cu_76da30a3__ZN66_INTERNAL_1ac03b01_35_shaders_intersects_line_query_2d_cu_76da30a36thrust12placeholders2_2E[1];
.global .align 1 .b8 __nv_static_57__1ac03b01_35_shaders_intersects_line_query_2d_cu_76da30a3__ZN66_INTERNAL_1ac03b01_35_shaders_intersects_line_query_2d_cu_76da30a36thrust12placeholders2_3E[1];
.global .align 1 .b8 __nv_static_57__1ac03b01_35_shaders_intersects_line_query_2d_cu_76da30a3__ZN66_INTERNAL_1ac03b01_35_shaders_intersects_line_query_2d_cu_76da30a36thrust12placeholders2_4E[1];
.global .align 1 .b8 __nv_static_57__1ac03b01_35_shaders_intersects_line_query_2d_cu_76da30a3__ZN66_INTERNAL_1ac03b01_35_shaders_intersects_line_query_2d_cu_76da30a36thrust12placeholders2_5E[1];
.global .align 1 .b8 __nv_static_57__1ac03b01_35_shaders_intersects_line_query_2d_cu_76da30a3__ZN66_INTERNAL_1ac03b01_35_shaders_intersects_line_query_2d_cu_76da30a36thrust12placeholders2_6E[1];
.global .align 1 .b8 __nv_static_57__1ac03b01_35_shaders_intersects_line_query_2d_cu_76da30a3__ZN66_INTERNAL_1ac03b01_35_shaders_intersects_line_query_2d_cu_76da30a36thrust12placeholders2_7E[1];
.global .align 1 .b8 __nv_static_57__1ac03b01_35_shaders_intersects_line_query_2d_cu_76da30a3__ZN66_INTERNAL_1ac03b01_35_shaders_intersects_line_query_2d_cu_76da30a36thrust12placeholders2_8E[1];
.global .align 1 .b8 __nv_static_57__1ac03b01_35_shaders_intersects_line_query_2d_cu_76da30a3__ZN66_INTERNAL_1ac03b01_35_shaders_intersects_line_query_2d_cu_76da30a36thrust12placeholders2_9E[1];
.global .align 1 .b8 __nv_static_57__1ac03b01_35_shaders_intersects_line_query_2d_cu_76da30a3__ZN66_INTERNAL_1ac03b01_35_shaders_intersects_line_query_2d_cu_76da30a36thrust12placeholders3_10E[1];
.global .align 1 .b8 __nv_static_57__1ac03b01_35_shaders_intersects_line_query_2d_cu_76da30a3__ZN66_INTERNAL_1ac03b01_35_shaders_intersects_line_query_2d_cu_76da30a36thrust3seqE[1];
.global .align 1 .b8 __nv_static_57__1ac03b01_35_shaders_intersects_line_query_2d_cu_76da30a3__ZN66_INTERNAL_1ac03b01_35_shaders_intersects_line_query_2d_cu_76da30a34cuda3std3__48in_placeE[1];
.global .align 1 .b8 __nv_static_57__1ac03b01_35_shaders_intersects_line_query_2d_cu_76da30a3__ZN66_INTERNAL_1ac03b01_35_shaders_intersects_line_query_2d_cu_76da30a34cuda3std6ranges3__45__cpo4swapE[1];
.global .align 1 .b8 __nv_static_57__1ac03b01_35_shaders_intersects_line_query_2d_cu_76da30a3__ZN66_INTERNAL_1ac03b01_35_shaders_intersects_line_query_2d_cu_76da30a34cuda3std6ranges3__45__cpo9iter_moveE[1];
.extern .const .align 8 .b8 params[64];

.visible .entry __intersection__intersects_line_query_2d()
{
	.reg .b32 	%r<5>;


	mov.u32 	%r3, 0;
	// begin inline asm
	call (%r2), _optix_get_payload, (%r3);
	// end inline asm
	ret;

}
	// .globl	__raygen__intersects_line_query_2d
.visible .entry __raygen__intersects_line_query_2d()
{
	.reg .pred 	%p<67>;
	.reg .f32 	%f<70>;
	.reg .b32 	%r<146>;
	.reg .f64 	%fd<13>;
	.reg .b64 	%rd<12>;


	// begin inline asm
	call (%r141), _optix_get_launch_index_x, ();
	// end inline asm
	cvt.u64.u32 	%rd11, %r141;
	ld.const.u64 	%rd2, [params+40];
	setp.le.u64 	%p1, %rd2, %rd11;
	@%p1 bra 	$L__BB1_39;

	ld.const.u64 	%rd7, [params+32];
	cvta.to.global.u64 	%rd3, %rd7;
	ld.const.u64 	%rd4, [params+48];
	// begin inline asm
	call (%r138), _optix_get_launch_dimension_x, ();
	// end inline asm

$L__BB1_2:
	shl.b64 	%rd8, %rd11, 5;
	add.s64 	%rd9, %rd3, %rd8;
	ld.global.v2.f64 	{%fd5, %fd6}, [%rd9];
	ld.global.v2.f64 	{%fd9, %fd10}, [%rd9+16];
	setp.lt.f64 	%p2, %fd9, %fd5;
	selp.f64 	%fd1, %fd9, %fd5, %p2;
	setp.lt.f64 	%p3, %fd10, %fd6;
	selp.f64 	%fd2, %fd10, %fd6, %p3;
	setp.lt.f64 	%p4, %fd5, %fd9;
	selp.f64 	%fd3, %fd9, %fd5, %p4;
	setp.lt.f64 	%p5, %fd6, %fd10;
	selp.f64 	%fd4, %fd10, %fd6, %p5;
	cvt.rn.f32.f64 	%f1, %fd1;
	setp.eq.f32 	%p6, %f1, 0f00000000;
	mov.f32 	%f62, 0f00000000;
	mov.f32 	%f59, %f62;
	@%p6 bra 	$L__BB1_11;

	setp.gt.f64 	%p7, %fd1, 0d8000000000000000;
	selp.f32 	%f2, 0f00000000, 0fFF800000, %p7;
	mov.b32 	%r3, %f2;
	and.b32  	%r24, %r3, -2147483648;
	or.b32  	%r25, %r24, 1;
	mov.b32 	%f3, %r25;
	mov.u32 	%r142, 0;
	mov.f32 	%f59, %f1;
	bra.uni 	$L__BB1_4;

$L__BB1_6:
	or.b32  	%r26, %r5, %r3;
	mov.b32 	%f36, %r26;
	setp.eq.f32 	%p10, %f36, 0f00000000;
	mov.f32 	%f59, %f2;
	@%p10 bra 	$L__BB1_10;

	setp.eq.f32 	%p11, %f4, 0f00000000;
	mov.f32 	%f59, %f3;
	@%p11 bra 	$L__BB1_10;

	setp.lt.f32 	%p12, %f4, %f2;
	setp.lt.f32 	%p13, %f4, 0f00000000;
	and.pred  	%p14, %p13, %p12;
	selp.s32 	%r27, -1, 0, %p14;
	add.s32 	%r28, %r27, %r5;
	setp.gt.f32 	%p15, %f4, 0f00000000;
	and.pred  	%p16, %p15, %p12;
	selp.u32 	%r29, 1, 0, %p16;
	add.s32 	%r30, %r28, %r29;
	setp.gt.f32 	%p17, %f4, %f2;
	and.pred  	%p18, %p13, %p17;
	selp.u32 	%r31, 1, 0, %p18;
	add.s32 	%r32, %r30, %r31;
	and.pred  	%p19, %p15, %p17;
	selp.s32 	%r33, -1, 0, %p19;
	add.s32 	%r34, %r32, %r33;
	mov.b32 	%f59, %r34;
	bra.uni 	$L__BB1_10;

$L__BB1_4:
	.pragma "nounroll";
	mov.f32 	%f4, %f59;
	mov.b32 	%r5, %f4;
	abs.f32 	%f34, %f4;
	setp.gtu.f32 	%p8, %f34, 0f7F800000;
	@%p8 bra 	$L__BB1_9;

	abs.f32 	%f35, %f2;
	setp.gtu.f32 	%p9, %f35, 0f7F800000;
	@%p9 bra 	$L__BB1_9;
	bra.uni 	$L__BB1_6;

$L__BB1_9:
	add.f32 	%f59, %f2, %f4;

$L__BB1_10:
	add.s32 	%r142, %r142, -1;
	setp.ne.s32 	%p20, %r142, -2;
	@%p20 bra 	$L__BB1_4;

$L__BB1_11:
	cvt.rn.f32.f64 	%f9, %fd2;
	setp.eq.f32 	%p21, %f9, 0f00000000;
	@%p21 bra 	$L__BB1_20;

	setp.gt.f64 	%p22, %fd2, 0d8000000000000000;
	selp.f32 	%f10, 0f00000000, 0fFF800000, %p22;
	mov.b32 	%r7, %f10;
	and.b32  	%r36, %r7, -2147483648;
	or.b32  	%r37, %r36, 1;
	mov.b32 	%f11, %r37;
	mov.u32 	%r143, 2;
	mov.f32 	%f62, %f9;
	bra.uni 	$L__BB1_13;

$L__BB1_15:
	or.b32  	%r38, %r9, %r7;
	mov.b32 	%f40, %r38;
	setp.eq.f32 	%p25, %f40, 0f00000000;
	mov.f32 	%f62, %f10;
	@%p25 bra 	$L__BB1_19;

	setp.eq.f32 	%p26, %f12, 0f00000000;
	mov.f32 	%f62, %f11;
	@%p26 bra 	$L__BB1_19;

	setp.lt.f32 	%p27, %f12, %f10;
	setp.lt.f32 	%p28, %f12, 0f00000000;
	and.pred  	%p29, %p28, %p27;
	selp.s32 	%r39, -1, 0, %p29;
	add.s32 	%r40, %r39, %r9;
	setp.gt.f32 	%p30, %f12, 0f00000000;
	and.pred  	%p31, %p30, %p27;
	selp.u32 	%r41, 1, 0, %p31;
	add.s32 	%r42, %r40, %r41;
	setp.gt.f32 	%p32, %f12, %f10;
	and.pred  	%p33, %p28, %p32;
	selp.u32 	%r43, 1, 0, %p33;
	add.s32 	%r44, %r42, %r43;
	and.pred  	%p34, %p30, %p32;
	selp.s32 	%r45, -1, 0, %p34;
	add.s32 	%r46, %r44, %r45;
	mov.b32 	%f62, %r46;
	bra.uni 	$L__BB1_19;

$L__BB1_13:
	.pragma "nounroll";
	mov.f32 	%f12, %f62;
	mov.b32 	%r9, %f12;
	abs.f32 	%f38, %f12;
	setp.gtu.f32 	%p23, %f38, 0f7F800000;
	@%p23 bra 	$L__BB1_18;

	abs.f32 	%f39, %f10;
	setp.gtu.f32 	%p24, %f39, 0f7F800000;
	@%p24 bra 	$L__BB1_18;
	bra.uni 	$L__BB1_15;

$L__BB1_18:
	add.f32 	%f62, %f10, %f12;

$L__BB1_19:
	add.s32 	%r143, %r143, -1;
	setp.ne.s32 	%p35, %r143, 0;
	@%p35 bra 	$L__BB1_13;

$L__BB1_20:
	cvt.rn.f32.f64 	%f17, %fd3;
	setp.eq.f32 	%p36, %f17, 0f00000000;
	mov.f32 	%f68, 0f00000000;
	mov.f32 	%f65, %f68;
	@%p36 bra 	$L__BB1_29;

	setp.lt.f64 	%p37, %fd3, 0d0000000000000000;
	selp.f32 	%f18, 0f00000000, 0f7F800000, %p37;
	mov.b32 	%r11, %f18;
	mov.u32 	%r144, 2;
	mov.f32 	%f19, 0f00000001;
	mov.f32 	%f65, %f17;
	bra.uni 	$L__BB1_22;

$L__BB1_24:
	or.b32  	%r48, %r13, %r11;
	mov.b32 	%f44, %r48;
	setp.eq.f32 	%p40, %f44, 0f00000000;
	mov.f32 	%f65, %f18;
	@%p40 bra 	$L__BB1_28;

	setp.eq.f32 	%p41, %f20, 0f00000000;
	mov.f32 	%f65, %f19;
	@%p41 bra 	$L__BB1_28;

	setp.lt.f32 	%p42, %f20, %f18;
	setp.lt.f32 	%p43, %f20, 0f00000000;
	and.pred  	%p44, %p43, %p42;
	selp.s32 	%r49, -1, 0, %p44;
	add.s32 	%r50, %r49, %r13;
	setp.gt.f32 	%p45, %f20, 0f00000000;
	and.pred  	%p46, %p45, %p42;
	selp.u32 	%r51, 1, 0, %p46;
	add.s32 	%r52, %r50, %r51;
	setp.gt.f32 	%p47, %f20, %f18;
	and.pred  	%p48, %p43, %p47;
	selp.u32 	%r53, 1, 0, %p48;
	add.s32 	%r54, %r52, %r53;
	and.pred  	%p49, %p45, %p47;
	selp.s32 	%r55, -1, 0, %p49;
	add.s32 	%r56, %r54, %r55;
	mov.b32 	%f65, %r56;
	bra.uni 	$L__BB1_28;

$L__BB1_22:
	.pragma "nounroll";
	mov.f32 	%f20, %f65;
	mov.b32 	%r13, %f20;
	abs.f32 	%f42, %f20;
	setp.gtu.f32 	%p38, %f42, 0f7F800000;
	@%p38 bra 	$L__BB1_27;

	abs.f32 	%f43, %f18;
	setp.gtu.f32 	%p39, %f43, 0f7F800000;
	@%p39 bra 	$L__BB1_27;
	bra.uni 	$L__BB1_24;

$L__BB1_27:
	add.f32 	%f65, %f18, %f20;

$L__BB1_28:
	add.s32 	%r144, %r144, -1;
	setp.ne.s32 	%p50, %r144, 0;
	@%p50 bra 	$L__BB1_22;

$L__BB1_29:
	cvt.rn.f32.f64 	%f25, %fd4;
	setp.eq.f32 	%p51, %f25, 0f00000000;
	@%p51 bra 	$L__BB1_38;

	setp.lt.f64 	%p52, %fd4, 0d0000000000000000;
	selp.f32 	%f26, 0f00000000, 0f7F800000, %p52;
	mov.b32 	%r15, %f26;
	mov.u32 	%r145, 2;
	mov.f32 	%f27, 0f00000001;
	mov.f32 	%f68, %f25;
	bra.uni 	$L__BB1_31;

$L__BB1_33:
	or.b32  	%r58, %r17, %r15;
	mov.b32 	%f48, %r58;
	setp.eq.f32 	%p55, %f48, 0f00000000;
	mov.f32 	%f68, %f26;
	@%p55 bra 	$L__BB1_37;

	setp.eq.f32 	%p56, %f28, 0f00000000;
	mov.f32 	%f68, %f27;
	@%p56 bra 	$L__BB1_37;

	setp.lt.f32 	%p57, %f28, %f26;
	setp.lt.f32 	%p58, %f28, 0f00000000;
	and.pred  	%p59, %p58, %p57;
	selp.s32 	%r59, -1, 0, %p59;
	add.s32 	%r60, %r59, %r17;
	setp.gt.f32 	%p60, %f28, 0f00000000;
	and.pred  	%p61, %p60, %p57;
	selp.u32 	%r61, 1, 0, %p61;
	add.s32 	%r62, %r60, %r61;
	setp.gt.f32 	%p62, %f28, %f26;
	and.pred  	%p63, %p58, %p62;
	selp.u32 	%r63, 1, 0, %p63;
	add.s32 	%r64, %r62, %r63;
	and.pred  	%p64, %p60, %p62;
	selp.s32 	%r65, -1, 0, %p64;
	add.s32 	%r66, %r64, %r65;
	mov.b32 	%f68, %r66;
	bra.uni 	$L__BB1_37;

$L__BB1_31:
	.pragma "nounroll";
	mov.f32 	%f28, %f68;
	mov.b32 	%r17, %f28;
	abs.f32 	%f46, %f28;
	setp.gtu.f32 	%p53, %f46, 0f7F800000;
	@%p53 bra 	$L__BB1_36;

	abs.f32 	%f47, %f26;
	setp.gtu.f32 	%p54, %f47, 0f7F800000;
	@%p54 bra 	$L__BB1_36;
	bra.uni 	$L__BB1_33;

$L__BB1_36:
	add.f32 	%f68, %f26, %f28;

$L__BB1_37:
	add.s32 	%r145, %r145, -1;
	setp.ne.s32 	%p65, %r145, 0;
	@%p65 bra 	$L__BB1_31;

$L__BB1_38:
	sub.f32 	%f53, %f68, %f62;
	sub.f32 	%f52, %f65, %f59;
	mov.f32 	%f56, 0f3F800000;
	mov.f32 	%f57, 0f00000000;
	mov.u32 	%r100, 255;
	mov.u32 	%r105, 1;
	mov.u32 	%r137, 0;
	// begin inline asm
	call(%r67,%r68,%r69,%r70,%r71,%r72,%r73,%r74,%r75,%r76,%r77,%r78,%r79,%r80,%r81,%r82,%r83,%r84,%r85,%r86,%r87,%r88,%r89,%r90,%r91,%r92,%r93,%r94,%r95,%r96,%r97,%r98),_optix_trace_typed_32,(%r137,%rd4,%f59,%f62,%f57,%f52,%f53,%f57,%f57,%f56,%f57,%r100,%r137,%r137,%r105,%r137,%r105,%r141,%r137,%r137,%r137,%r137,%r137,%r137,%r137,%r137,%r137,%r137,%r137,%r137,%r137,%r137,%r137,%r137,%r137,%r137,%r137,%r137,%r137,%r137,%r137,%r137,%r137,%r137,%r137,%r137,%r137,%r137,%r137);
	// end inline asm
	add.s32 	%r141, %r67, %r138;
	cvt.u64.u32 	%rd11, %r141;
	setp.gt.u64 	%p66, %rd2, %rd11;
	@%p66 bra 	$L__BB1_2;

$L__BB1_39:
	ret;

}
	// .weak	_ZN3cub17CUB_200200_750_NS11EmptyKernelIvEEvv
.weak .entry _ZN3cub17CUB_200200_750_NS11EmptyKernelIvEEvv()
{



	ret;

}

